{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to deep learning\n",
    "\n",
    "We can recall the perceptrion algorithm lessons in `..\\1_supervised_learning\\02 Classification.ipynb`. We will move from there forward. Here we remind:\n",
    "\"\"\"\n",
    "More generally, the steps can be represented by a perceptrion diagram:\n",
    " * inputs\n",
    " * weights (linear function coefficients, + bias)\n",
    " * linear function\n",
    " * step function\n",
    " * output\n",
    "\n",
    "<img src=\"../1_supervised_learning/images/2.03_perceptron_diagram.png\" alt=\"Drawing\" style=\"width: 700px\"/>\n",
    "\n",
    "The way to update the function is as follows:\n",
    " * initialise function coefficients\n",
    " * evaluate if points are in the correct semi-space\n",
    " * consider only the wrongly predicted, and loops through them:\n",
    "     * if the point is positive, but predicted negative, the weights are increased\n",
    "     * if the poins is negative, but predicted positive, the weights are dicreased\n",
    "\n",
    "Formula to update weights:\n",
    "\\begin{equation*}\n",
    "W = W \\pm \\alpha X\n",
    "b = b \\pm \\alpha\n",
    "\\end{equation*}\n",
    "where $\\pm$ is applied accordingly to how the point is misclassified\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Functions\n",
    "\n",
    "Generally, error functions must be:\n",
    " * Differentiable\n",
    " * Continuous\n",
    "\n",
    "This is to be able to use gradient descent on the error functions to train our models, minimising the error.\n",
    "\n",
    "<img src=\".\\images\\0.01_disc-cont.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "This can be done by moving from discrete predictions to continuous predictions (from {yes,no} to {67.4% yes}). To do this, we use a continuous activation function to be applied to our score (e.g. **sigmoid function**). \n",
    "\n",
    "The overall process is:\n",
    "\n",
    "#### 1 calculate the score for a point\n",
    "\n",
    "\\begin{equation*}\n",
    "\\newcommand{\\vect}[1]{\\boldsymbol{#1}}\n",
    "score = \\vect{Wx}+b\\\\\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $\\vect{W}$ is the weight matrix\n",
    " * $\\vect{x}$ is the feature vector\n",
    " * $\\vect{b}$ is the bias\n",
    "\n",
    "#### 2 calculate the probability of a point of being classified by applying the activation function\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "where:\n",
    " * $x$ is the score calculated above (distance from the separation function)\n",
    " \n",
    "\n",
    "<img src=\".\\images\\0.03_sigmoid.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "#### Scores and Predictions\n",
    "\n",
    "Therefore, our preceptrion will calculate scores and will spit out predictions are follow:\n",
    "\n",
    "<img src=\".\\images\\0.04_sigmoid-pred.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "<img src=\".\\images\\0.05_cont-pred.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "### Multi-class activation function: SofMax\n",
    "\n",
    "Softmax is the general case of the sigmoid for more than one class.\n",
    "\n",
    "\\begin{equation*}\n",
    "P(class_a) = \\frac{e^{Z_a}}{\\sum{e^{Z_i}}}\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $Z_a$ is the score of the point belonging to the $a$ class\n",
    " * $Z_i$ is the score of the point belonging to the $i$ class\n",
    " \n",
    "<img src=\".\\images\\0.06_softmax.PNG\" style=\"width: 600px;\"/>\n",
    "\n",
    "In Python, it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.35348071e-04, 9.99658510e-01, 6.14211417e-06])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input a list of numbers, and returns\n",
    "# the list of values given by the softmax function.\n",
    "def softmax(L):\n",
    "    total = sum(map(np.exp,L))\n",
    "    return np.array(list(map(lambda x:np.exp(x)/total,L)))\n",
    "\n",
    "# example\n",
    "softmax([4,12,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we output each probability of a data point being of a certain class. \n",
    "\n",
    "<img src=\".\\images\\0.07_softmax-out.PNG\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Likelyhood and Cross Entropy\n",
    "\n",
    "If we have two models and we want to understand which one is best. We calculate the scores for four points, and then their probability by applying the **Softmax** function. We pick the probability of them belonging to their actual classes. We multiply them, and that is a measure to compare models. The model on the right returns higher probability for the training data.\n",
    "\n",
    "<img src=\".\\images\\0.08_max-likelyhood.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "In order to maximise the probability (and minimize the error) we want to see how Max likelyhood and error are related. First, we want to calc the probability and maximise it. However, the product many (thousands) points might be tiny (very bad!!). So we can calculate the Max likelyhood differently, as the sum of the logarithms:\n",
    "\n",
    "\\begin{equation*}\n",
    "-\\sum{ln(P_i)}\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $P_i$ is the likelyhood of a single event to happen in relation to the given label.\n",
    "\n",
    "Since $0.0 \\le P_i\\le 1.0$, their $ln(P_i) \\le 0$, thus there is a minus in front of the sum. Therefore, we move from maximizing the probability to minimizing the cross entropy. We can see also the cross entropy as a way to calculate each point's error:\n",
    "\n",
    "<img src=\".\\images\\0.09_cross-entropy.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "Now, we took $P_i$ as the likelyhood of an event to happen for a given label. So we can introduce the label as a variable by expanding the forumla as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{Cross-Entropy} = -\\sum{y_i ln(P_i) + (1-y_i) ln(1-P_i)}\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $P_i$ is the probability of the i-th event to happen\n",
    " * $y_i$ is the label of the i-th event\n",
    "\n",
    "<img src=\".\\images\\0.10_cross-entropy.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "<img src=\".\\images\\0.11_cross-entropy.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "Here we run an example for the most likely combination (line 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = [1,1,0]\n",
    "p = [0.8,0.7,0.1]\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    r = map(lambda y,p: y*np.log(p)+(1-y)*np.log(1.0-p),Y,P)\n",
    "    return -sum(r)\n",
    "\n",
    "round(cross_entropy(y,p),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Cross-Entropy\n",
    "\n",
    "Now we assume to have $n=3$ random variables (the doors, ???representing the label of each data-point???), each with $m=3$  $categories=\\{duck,beaver,walrus\\}$, with different probabilities to happen:\n",
    "\n",
    "<img src=\".\\images\\0.12_multi-cross-entropy.PNG\" style=\"width: 600px;\" />\n",
    "\n",
    "So we have the probability matrix:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "P_{1,1} &   P_{1,2} & \\dots     &   P_{1,m} \\\\\n",
    "P_{2,1} &   P_{2,2} & \\dots     &   P_{2,m} \\\\\n",
    "\\vdots  &  \\vdots   &   \\vdots  &   \\vdots  \\\\   \n",
    "P_{n,1} &   P_{n,2} & \\dots     &   P_{n,m} \\\\\n",
    "            \\end{bmatrix}\n",
    "            }_{\\mathbf{P}}\n",
    "            \\ ,\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "y_{1,1} &   y_{1,2} & \\dots     &   y_{1,m} \\\\\n",
    "y_{2,1} &   y_{2,2} & \\dots     &   y_{2,m} \\\\\n",
    "\\vdots  &  \\vdots   &   \\vdots  &   \\vdots  \\\\   \n",
    "y_{n,1} &   y_{n,2} & \\dots     &   y_{n,m} \\\\\n",
    "            \\end{bmatrix}\n",
    "            }_{\\mathbf{y}}\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $\\mathbf{P}$ is the probability matrix with n categories and m random variables\n",
    " * $\\mathbf{y}$ is the label matrix with the classified categories\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{Cross-Entropy} = -\\sum_{i=1}^{n}\\sum_{j=1}^{m} y_{i,j} \\ln(P_{i,j})\n",
    "\\end{equation*}\n",
    "\n",
    "----\n",
    "\n",
    "The example shown above is coded here below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4769384801388235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = [[1,0,0],\n",
    "     [0,0,0],\n",
    "     [0,1,1]]\n",
    "p = [[0.7,0.3,0.1],\n",
    "     [0.2,0.4,0.5],\n",
    "     [0.1,0.3,0.4]]\n",
    "\n",
    "# to np array\n",
    "y = np.array(y)\n",
    "p = np.array(p)\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    r = map(lambda y,p: y*np.log(p),Y,P)\n",
    "    return -sum(r)[0]\n",
    "\n",
    "cross_entropy(y.reshape(-1,1),p.reshape(-1,1)) # arrays are processed flattened for better performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convention, we take the average cross-entropy to obtain an error function.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{Cross-Entropy} = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m} y_{i,j} \\ln(P_{i,j})\n",
    "\\end{equation*}\n",
    "\n",
    "Now, we know that $P_i = \\hat{y}$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{Cross-Entropy} = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m} y_{i,j} \\ln(\\hat{y_{i,j}})\n",
    "\\end{equation*}\n",
    "\n",
    "And $\\hat{y} = \\sigma(\\vect{Wx}+b)$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{Cross-Entropy} = -\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{m} y_{i,j} \\ln(\\sigma(w_{i,j}x_{i,j}+b_{i}))\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    " * $n$ is the number of random variables - i.e. of samples\n",
    " * $m$ is the number of categories\n",
    " * $w_{i,j}$ is the weight of the i-th feature, j-th category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### k\n",
    "\n",
    "**The entropy of a probability distribution is as follows:**\n",
    "\n",
    "$\\sum{P(i) log P(i)}$\n",
    "\n",
    "We assume that we know the probability P for each i. The term i indicates a discrete event that could mean different things depending on the scenario you are dealing.\n",
    "\n",
    "**For continuous variables, it can be written using the integral form:**\n",
    "\n",
    "$\\int{P(x) log P(x)dx}$\n",
    "\n",
    "Here, x is a continuous variable, and P(x) is the probability density function.\n",
    "\n",
    "In both discrete and continuous variable cases, we are calculating the expectation (average) of the negative log probability which is the theoretical minimum encoding size of the information from the event x.\n",
    "\n",
    "So, the above formula can be re-written in the expectation form as follows:\n",
    "$E_{x~P} (- log P(x))$\n",
    "\n",
    "where:\n",
    " * x~P means that we calculate the expectation with the probability distribution P.\n",
    "\n",
    "**In short, the entropy tells us the theoretical minimum average encoding size for events that follow a particular probability distribution.**\n",
    "\n",
    "*Cross-entropy ≥ Entropy*\n",
    "\n",
    "Commonly, the cross-entropy is expressed using H as follows:\n",
    "_H(P, Q) = E (subscript (x~P) [- log Q(x)])_\n",
    "\n",
    "H(P, Q) means that we calculate the expectation using P and the encoding size using Q. As such, H(P, Q) and H(Q, P) is not necessarily the same except when Q=P, in which case H(P, Q) = H(P, P) = H(P) and it becomes the entropy itself.\n",
    "\n",
    "This point is subtle but essential. For the expectation, we should use the true probability P as that tells the distribution of events. For the encoding size, we should use Q as that is used to encode messages.\n",
    "\n",
    "Since the entropy is the theoretical minimum average size, the cross-entropy is higher than or equal to the entropy but not less than that.\n",
    "\n",
    "In other words, if our estimate is perfect, Q = P and, hence, H(P, Q)=H(P). Otherwise, H(P, Q) > H(P).\n",
    "he cross-entropy compares the model’s prediction with the label which is the true probability distribution. The cross-entropy goes down as the prediction gets more and more accurate. It becomes zero if the prediction is perfect. As such, the cross-entropy can be a loss function to train a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "link: https://www.youtube.com/watch?v=V5kkHldUlVU&feature=youtu.be\n",
    "\n",
    "Gradient Calculation\n",
    "In the last few videos, we learned that in order to minimize the error function, we need to take some derivatives. So let's get our hands dirty and actually compute the derivative of the error function. The first thing to notice is that the sigmoid function has a really nice derivative. Namely,\n",
    "\n",
    "$\\sigma'(x)=\\sigma(x)(1−\\sigma(x))$\n",
    "\n",
    "And now, let's recall that if we have mm points labelled $x^{(1)}, x^{(2)}, \\ldots, x^{(m)}$ , the error formula is:\n",
    "\n",
    "$E = \\frac{1}{m} \\sum_{i=1}^m \\left( y_i \\ln(\\hat{y_i}) + (1-y_i) \\ln (1-\\hat{y_i}) \\right)$\n",
    "\n",
    "where the prediction is given by $\\hat{y_i} = \\sigma(Wx^{(i)} + b)$. \n",
    "\n",
    "\n",
    "Our goal is to calculate the gradient of E, at a point $x = (x_1, \\ldots, x_n)$, given by the partial derivatives\n",
    "\n",
    "$\\nabla E =\\left(\\frac{\\partial}{\\partial w_1}E, \\cdots, \\frac{\\partial}{\\partial w_n}E, \\frac{\\partial}{\\partial b}E \\right)$\n",
    "\n",
    "To simplify our calculations, we'll actually think of the error that each point produces, and calculate the derivative of this error. The total error, then, is the average of the errors at all the points. The error produced by each point is, simply,\n",
    "\n",
    "$E = - y \\ln(\\hat{y}) - (1-y) \\ln (1-\\hat{y})$\n",
    "\n",
    "In order to calculate the derivative of this error with respect to the weights, we'll first calculate $\\frac{\\partial}{\\partial w_j} \\hat{y}$. Recall that $\\hat{y} = \\sigma(Wx+b)$, so:\n",
    "![](.\\images\\codecogseqn-43.gif)\n",
    "\n",
    "The last equality is because the only term in the sum which is not a constant with respect to $w_jw$ is precisely $w_j x_j$, which clearly has derivative x_j.\n",
    "Now, we can go ahead and calculate the derivative of the error $E$ at a point $x$, with respect to the weight $w_j$.\n",
    "\n",
    "![](.\\images\\0.14_codecogseqn-60-2.png)\n",
    "\n",
    "A similar calculation will show us that\n",
    "\n",
    "$\\frac{\\partial}{\\partial b} E = -(y-\\hat{y})$\n",
    "\n",
    "This actually tells us something very important. For a point with coordinates $(x_1, \\ldots, x_n)$, label $y$, and prediction $\\hat{y}$, the gradient of the error function at that point is $\\left(-(y - \\hat{y})x_1, \\cdots, -(y - \\hat{y})x_n, -(y - \\hat{y}) \\right)$. In summary, the gradient is\n",
    "\n",
    "$\\nabla E = −(y−\\hat{y})(x_1,\\ldots,x_n,1)$\n",
    "\n",
    "If you think about it, this is fascinating. The gradient is actually a scalar times the coordinates of the point! And what is the scalar? Nothing less than a multiple of the difference between the label and the prediction. What significance does this have?\n",
    "\n",
    " * Closer the label to the prediction, smaller the gradient\n",
    "\n",
    "So, a small gradient means we'll change our coordinates by a little bit, and a large gradient means we'll change our coordinates by a lot.\n",
    "\n",
    "If this sounds anything like the perceptron algorithm, this is no coincidence! We'll see it in a bit.\n",
    "\n",
    "### Gradient Descent Step\n",
    "\n",
    "Therefore, since the gradient descent step simply consists in subtracting a multiple of the gradient of the error function at every point, then this updates the weights in the following way:\n",
    "\n",
    "$w_i' \\leftarrow w_i - \\alpha [-(y - \\hat{y}) x_i]$,\n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$w_i' \\leftarrow w_i + \\alpha (y - \\hat{y}) x_i$.\n",
    "\n",
    "Similarly, it updates the bias in the following way:\n",
    "\n",
    "$b' \\leftarrow b + \\alpha (y - \\hat{y})$,\n",
    "\n",
    "Note: Since we've taken the average of the errors, the term we are adding should be $\\frac{1}{m} \\cdot \\alpha$ instead of $\\alpha$, but as $\\alpha$ is a constant, then in order to simplify calculations, we'll just take $\\frac{1}{m} \\cdot \\alpha$ to be our learning rate, and abuse the notation by just calling it $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear data\n",
    "\n",
    "Now we wil try to fit a non-linear function to calssify (separate) data.\n",
    "\n",
    "![](.\\images\\0.15_non-lin_models.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeedForward\n",
    "\n",
    "Hte feed-forward of a NN is identical to apply a bunch of functions over and over.\n",
    "\n",
    "![](.\\images\\0.16_feed-forward.PNG)\n",
    "\n",
    "Basically, for n layers:\n",
    "\n",
    "$ \\hat{y} = \\sigma W_n(\\sigma W_{n-1}(\\ldots \\sigma W_2( \\sigma W_1(X) ) \\ldots))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function\n",
    "\n",
    "![](.\\images\\0.17_error-func.PNG)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
